{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common functions and prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start, \n",
    "-  create a python venv, and `pip install -r requirements.txt`.\n",
    "-  make a copy of `local.env` to `.env`, configure your environment in `.env`.\n",
    "-  adjust data in the `data` folder based on your configuration.\n",
    "-  run each scripts in the `ingest` folder to process and ingest the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "from openai.types.chat import ChatCompletionMessage\n",
    "\n",
    "sys.path.append('./utils')\n",
    "from loadenv import LLMConfig, RobotConfig\n",
    "sys.path.append('./chat/functions')\n",
    "from robot_general import get_robots, search_robot_manuals\n",
    "\n",
    "aoai_config = LLMConfig()\n",
    "aoai_api_version, aoai_deployment = aoai_config.chat[\"api_version\"], aoai_config.chat['deployment']\n",
    "\n",
    "def print_llm_messages(msg):\n",
    "  print(\"-----------------------------------LLM message(s)---------------------------------------------------\")\n",
    "  pp = pprint.PrettyPrinter(width=160)\n",
    "  if isinstance(msg, list):\n",
    "    for m in msg:\n",
    "      if isinstance(m, dict):\n",
    "        pp.pprint(m)\n",
    "      elif isinstance(m, ChatCompletionMessage):\n",
    "        pp.pprint(dict(m))\n",
    "  if isinstance(msg, ChatCompletionMessage):\n",
    "    pp.pprint(dict(msg))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=get_robots(\"petoi_cat\")\n",
    "pprint.pprint(json.loads(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=search_robot_manuals(\"api for petoi cat\")\n",
    "pprint.pprint(json.loads(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = {\"role\": \"system\", \"content\": \n",
    "    \"\"\"You are an expert who helps people troubleshoot robot related issues.\n",
    "    A robot's name is typically prefixed with its kind, for example, the kind for spot_jr is spot.\n",
    "    Try identify the kind of the robot first so you can narrow down when searching for info in tools. \n",
    "    Respond only with the info from the provided context or tools.\n",
    "    If you don't know the answer, respond with \"I don't know\".\"\"\"}\n",
    "# user_message = {\"role\": \"user\", \"content\": \n",
    "#     \"\"\"My robot spot_jr can't make left turns. When was it purchased and last serviced? What is the API that I can call?\"\"\"}\n",
    "user_message = {\"role\": \"user\", \"content\": \n",
    "    \"\"\"My robot spot_jr can't make left turns. When was it last serviced?\"\"\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_robots\",\n",
    "      \"description\": \"Get the name, kind, purchase date, and manufacturer of currently registered robots\",\n",
    "      \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "              \"name\": {\"type\": \"string\", \"description\": \"The name of the robot to get information about\"},\n",
    "              \"kind\": {\"type\": \"string\", \"description\": \"the kind of the robot to get information about\"},\n",
    "          },\n",
    "          \"required\": [],\n",
    "      },\n",
    "    },\n",
    "  },\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"search_robot_manuals\",\n",
    "      \"description\": \"Search the robot manuals for robot faults, troubleshooting guides, development API etc.\",\n",
    "      \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "              \"query\": {\"type\": \"string\", \"description\": \"The user's query for semantic and vector search\"},\n",
    "              \"kind\": {\"type\": \"string\", \"description\": \"the kind of the robot to get information about\"},\n",
    "          },\n",
    "          \"required\": [\"query\"],\n",
    "      },\n",
    "    },\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "aoai = AzureOpenAI(api_version=aoai_api_version)\n",
    "messages = [system_message, user_message]\n",
    "\n",
    "num_turns = 0\n",
    "while True:\n",
    "  print_llm_messages(messages)\n",
    "  response = aoai.chat.completions.create(\n",
    "      model=aoai_deployment,\n",
    "      messages=messages,\n",
    "      tools=tools,\n",
    "      tool_choice=\"auto\", # let the model decide. \"none\" means don't call, or specify which tool to always call. \n",
    "  )\n",
    "  result_message = response.choices[0].message\n",
    "  tool_calls = result_message.tool_calls\n",
    "\n",
    "  # no more tools to call\n",
    "  if not tool_calls:\n",
    "    print_llm_messages(result_message)\n",
    "    break\n",
    "\n",
    "  # doesn't make sense to call tools over and over\n",
    "  if num_turns > 2:\n",
    "    logging.warning(\"force terminated.\")\n",
    "    print_llm_messages(result_message)\n",
    "    break\n",
    "\n",
    "  # call tools, add tool results to messages\n",
    "  result_message.content = \"\" if not result_message.content else result_message.content\n",
    "  messages.append(result_message)\n",
    "  for tool_call in tool_calls:\n",
    "    if tool_call.function.name == \"get_robots\":\n",
    "      args = json.loads(tool_call.function.arguments)\n",
    "      function_result = get_robots(**args)\n",
    "      messages.append({\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": tool_call.function.name,\n",
    "        \"content\": function_result\n",
    "      })\n",
    "      num_turns += 1\n",
    "    elif tool_call.function.name == \"search_robot_manuals\":\n",
    "      args = json.loads(tool_call.function.arguments)\n",
    "      function_result = search_robot_manuals(**args)\n",
    "      messages.append({\n",
    "        \"tool_call_id\": tool_call.id,\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": tool_call.function.name,\n",
    "        \"content\": function_result\n",
    "      \n",
    "      })\n",
    "      num_turns += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debuggability\n",
    "\n",
    "|Options|Pros|Cons|\n",
    "|:-----|:---|:---|\n",
    "|Python logging|<ul><li>With logging level set to INFO, http requests/responses are logged with headers.</li></ul>|<ul><li>Prompts are not logged automatically.</li><li>Format is hard to read.</li></ul>|\n",
    "|Azure Monitor|<ul><li>Out of the box dashboard with metrics for tokens, requests etc.</li> <li>With diagnostics settings enabled on Azure OpenAI, http requests/responses are logged with headers.</li></ul>|<ul><li>Prompts are not automatically logged.</li></ul>|\n",
    "|PPrint|<ul><li>Prompts can be manually logged in easy to read format.</li></ul>|<ul><li>Developer toil.</li></ul>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prompt flow with Azure OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences in code\n",
    "\n",
    "-  Must write [flow.dag.yaml](./chat_flow/flow.dag.yaml).\n",
    "-  Certain variables, such as [Azure OpenAI deployment name](./chat_flow/flow.dag.yaml#L24), cannot be loaded from .env unless you write your own code.\n",
    "-  prompt flow tools must be annotated in certain ways. They are not the same as `tools` in OpenAI API. For example, here's a [prompt flow tool](./chat_flow/llm_tools.py)  that defines OpenAI `tools`.\n",
    "-  Flow must run from the flow folder, which makes [importing existing Python files in other folders complicated](./chat_flow/agent_tool.py).\n",
    "-  If you want to use `connections` in your non-prompt-flow code, you need to [translate](./chat_flow/agent_tool.py#L16) prompt flow `AzureOpenAIConnection` to openai `AzureOpenAI`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences in debuggability\n",
    "\n",
    "-  With VSCode prompt flow extension, you can see the inputs/outputs of LLM calls automatically in the `prompt flow tab` without having to create any flow run.\n",
    "-  You can also use `pf run create -f run.yaml --variant \"${node.variant}\"` to create a run for each variant, and then use `pf run visualize --names \"run1,run2...\"` to visualize multiple runs and compare their output in a nice table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.tools import  Tool, tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"search_robot_manuals\")\n",
    "def search_robot_manuals_tool(query: str, kind: str = None) -> str:\n",
    "  \"\"\"Use this tool to search the robot manuals for robot faults, troubleshooting guides, development API etc.\n",
    "    It doesn't have any other info such as logs, manuals, or maintenance records.\"\"\"\n",
    "  return search_robot_manuals(query, kind)\n",
    "\n",
    "@tool(\"get_robots_registration\")\n",
    "def get_robots_tool(name: str = None, kind: str = None) -> str:\n",
    "  \"\"\"Use this tool to get robot registration info only, such as name, kind, purchase date, and manufacturer.\n",
    "    It doesn't have any other info such as logs, training manual, troubleshooting guides, or maintenance records.\"\"\"\n",
    "  return get_robots(name, kind)\n",
    "\n",
    "lc_tools = [search_robot_manuals_tool, get_robots_tool]\n",
    "lc_aoai = AzureChatOpenAI(azure_deployment=aoai_deployment, openai_api_version=aoai_api_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community and Composability\n",
    "\n",
    "-  With the community OpenAPI agent, you can make LLM call any API with an OpenAPI spec, not just GET, but also any operations.\n",
    "-  LangChain Agent is a model (an LLM). AgentExecutor is a chain(RunnableSerializable). So to use an existing agent as a tool, you can pass AgentExecutor.run method. Only the `run` method works, `invoke` doesn't. But `run` is deprecated.\n",
    "-  There a bigger question of what is the right agent approach? When the agents perform completely different tasks in different domains, research from Microsoft AutoGen shows that having each agent specializing on a specific domain renders better results, even though the underlying model is the same.\n",
    "    -  one agent with multiple tools?\n",
    "    -  one orchestrator agent with multiple expert agents? \n",
    "    -  group of agents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start OpenAPI functions that expose maintenance data:\n",
    "\n",
    "```sh\n",
    "flask --app chat/functions/petoi.py run --port 3000\n",
    "flask --app chat/functions/spot.py run --port 5000\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 1: Use multiple Community Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
    "from langchain.agents.agent_toolkits.openapi import planner\n",
    "from langchain.requests import RequestsWrapper\n",
    "import yaml\n",
    "\n",
    "robotConfig = RobotConfig()\n",
    "for kind in robotConfig.kinds:\n",
    "  with open(kind['api_spec']) as f:\n",
    "    raw_api_spec = yaml.load(f, Loader=yaml.Loader)\n",
    "  api_spec = reduce_openapi_spec(raw_api_spec)\n",
    "  requests_wrapper = RequestsWrapper()\n",
    "  agent_executor: AgentExecutor = planner.create_openapi_agent(api_spec, requests_wrapper, lc_aoai)\n",
    "  # AgentExecutor is a chain\n",
    "  agent_tool = Tool.from_function(\n",
    "    func=agent_executor.run,\n",
    "    name=f\"get_{kind['name']}_maintenance_records\",\n",
    "    description=f\"Tool for accessing maintenance records for {kind['name']} robots.\")\n",
    "\n",
    "\n",
    "  lc_tools.append(agent_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  SystemMessage(content=system_message['content']),\n",
    "  HumanMessage(content=user_message['content']),\n",
    "  MessagesPlaceholder(variable_name=\"agent_scratchpad\")])\n",
    "\n",
    "agent = create_openai_tools_agent(lc_aoai, lc_tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=lc_tools, verbose=True)\n",
    "result = agent_executor({})\n",
    "pprint.pprint(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# This is what the openapi agent, the json agent, and the requests tool work together to answer the question\n",
    "###\n",
    "\n",
    "# #### use the json tools to figure out what is the base url based on the spec\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#   SystemMessage(content=JSON_PREFIX + JSON_SUFFIX),\n",
    "#   HumanMessage(content=\"what's the base url for my api calls?\"),\n",
    "#   MessagesPlaceholder(variable_name=\"agent_scratchpad\")])\n",
    "\n",
    "# openapi_agent = create_openai_tools_agent(lc_aoai, json_tools, prompt=prompt)\n",
    "# openapi_agent_executor = AgentExecutor(agent = openapi_agent, tools=json_tools, return_intermediate_steps=True)\n",
    "# result = openapi_agent_executor({})\n",
    "# pprint.pprint(result)\n",
    "\n",
    "# #### use the json tools to figure out which api to call based on the spec\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#   SystemMessage(content=JSON_PREFIX + JSON_SUFFIX),\n",
    "#   HumanMessage(content=\"can you get the maintenance record for a robot called spot_jr?\"),\n",
    "#   MessagesPlaceholder(variable_name=\"agent_scratchpad\")])\n",
    "\n",
    "# openapi_agent = create_openai_tools_agent(lc_aoai, json_tools, prompt=prompt)\n",
    "# openapi_agent_executor = AgentExecutor(agent = openapi_agent, tools=json_tools, return_intermediate_steps=True)\n",
    "# result = openapi_agent_executor({})\n",
    "# pprint.pprint(result)\n",
    "\n",
    "#### use the requests tool to make the call\n",
    "# combo = \"\"\"\n",
    "# You are an agent designed to answer questions by making web API calls using the following context:\n",
    "\n",
    "# Context:\n",
    "# The base URL for your API calls is \"http://localhost:5000\".\n",
    "# The maintenance records for the robot called spot_jr can be retrieved using the following endpoint: `/maintenance/spot_jr`. The response will include details such as the maintenance date, description, next maintenance date, and remarks.\n",
    "\n",
    "# Ensure you compose the correct url to send the requests.\n",
    "\n",
    "# \"\"\"\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#   SystemMessage(content=combo),\n",
    "#   HumanMessage(content=\"can you get the maintenance record for a robot called spot_jr?\"),\n",
    "#   MessagesPlaceholder(variable_name=\"agent_scratchpad\")])\n",
    "\n",
    "# openapi_agent = create_openai_tools_agent(lc_aoai, [requests_tool], prompt=prompt)\n",
    "# openapi_agent_executor = AgentExecutor(agent = openapi_agent, tools=[requests_tool], return_intermediate_steps=True)\n",
    "# result = openapi_agent_executor({})\n",
    "# pprint.pprint(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approach 2: Flatten the community tools and provide them to a single agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.requests.tool import RequestsGetTool\n",
    "from langchain.requests import TextRequestsWrapper\n",
    "requests_wrapper = TextRequestsWrapper()\n",
    "requests_tool = RequestsGetTool(requests_wrapper=requests_wrapper)\n",
    "lc_tools.append(requests_tool)\n",
    "\n",
    "from langchain_community.tools.json.tool import JsonSpec\n",
    "import yaml\n",
    "from langchain_community.agent_toolkits.json.toolkit import JsonToolkit\n",
    "\n",
    "# load OpenAPI spec\n",
    "robotConfig = RobotConfig()\n",
    "for kind in robotConfig.kinds:\n",
    "  with open(kind['api_spec']) as f:\n",
    "    raw_api_spec = yaml.load(f, Loader=yaml.FullLoader)\n",
    "  json_spec = JsonSpec(dict_=raw_api_spec, max_value_length=4000)\n",
    "  json_tools = JsonToolkit(spec=json_spec).get_tools()\n",
    "  for t in json_tools:\n",
    "    t.name = f\"{t.name}_{kind['name']}\"\n",
    "    t.description = f\"Helps understand the API specification for getting maintenance records for {kind['name']} robots. {t.description}\"\n",
    "    lc_tools.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maintenance_prompt = \"\"\"\n",
    "Important instructions for getting maintenance records for robots:\n",
    "####begin####\n",
    "To answer questions regarding robot maintenance records, you must understand the API specification for the robot and make web API calls.\n",
    "The API specification is a JSON blob that describes the API endpoints and the parameters needed to make the API calls.\n",
    "The json_spec_list_keys_<robot-kind> tool and the json_spec_get_value_<robot-kind> tool are provided to help you understand the API specification for that kind of robot.\n",
    "\n",
    "This is how you use the json_spec_list_keys_ and the json_spec_get_value_ tool:\n",
    "Your input to the json tools should be in the form of `data[\"key\"][0]` where `data` is the JSON blob you are interacting with, and the syntax used is Python.\n",
    "You should only use keys that you know for a fact exist. You must validate that a key exists by seeing it previously when calling json_spec_list_keys_ tool.\n",
    "If you have not seen a key in one of those responses, you cannot use it.\n",
    "You should only add one key at a time to the path. You cannot add multiple keys at once.\n",
    "Always begin your interaction with the json_spec_list_keys_ tools with input \"data\" to see what keys exist in the JSON.\n",
    "\n",
    "Using the these tools, your goal is to make the right API calls to find maintenance records. Follow these steps to get your answer:\n",
    "\n",
    "1. find the relevant api needed to answer the question.\n",
    "2. find the required parameters needed to make the api call.\n",
    "3. !!very important!! find the base URL for the APIs. The base URL will be used in the following step. Do not use any other URL as your base URL.\n",
    "4. compose the final URL and use the requests tool you have to make the requests needed to answer the question.\n",
    "####end####\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "  SystemMessage(content=system_message['content']),\n",
    "  SystemMessage(content=maintenance_prompt),\n",
    "  HumanMessage(content=user_message['content']),\n",
    "  MessagesPlaceholder(variable_name=\"agent_scratchpad\")])\n",
    "\n",
    "openapi_agent = create_openai_tools_agent(lc_aoai, lc_tools, prompt=prompt)\n",
    "openapi_agent_executor = AgentExecutor(agent = openapi_agent, tools=lc_tools, return_intermediate_steps=True)\n",
    "result = openapi_agent_executor({})\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences in code\n",
    "\n",
    "-  Must use `langchain.chat_models.AzureChatOpenAI`, although unlike `promptflow.connections.AzureOpenAIConnection`, LangChain does use the same OpenAI environment variables.\n",
    "-  Must use LangChain `HumanMessage`, `SystemMessage` data types, and annotations such as `@tool`.\n",
    "-  LangChain simplifies the code by automatically calling the tools, feed tools output back to LLM.\n",
    "    -  note that it's still calling the tools one by one, it is parallizable, just not implemented that way yet.\n",
    "-  good visibility with verbose=True, excellent in langsmith."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences in debuggability\n",
    "\n",
    "-  With LangSmith enabled by setting a few environment variables, all traces, including intermediate steps with inputs and outputs to LLMs, can be visualized in a nice UI.\n",
    "-  Without LangSmith, set `verbose=True` in the `AgentExecutor` also enables easy-to-visualize logging in the console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Agent vs. Single-Agent-Multi-Tool\n",
    "\n",
    "The following reasoning logic is required to make an API call given a user question and OpenAPI spec in JSON:\n",
    "1. Figure out which API name, what's the parameter, and what's the base URL to use to make the call based on a user question.\n",
    "2. For every step above, use the JSON tools to parse the OpenAPI specification:\n",
    "    1. List the keys in JSON\n",
    "    2. Find the value of the key\n",
    "3. Use the Request tool to make the call.\n",
    " \n",
    "GPT3.5 has no difficulty in Approach 1 where the JSON agent encapsulates the JSON parsing logic. However, with Approach 2, the instructions and the tools are flattened. More reasoning capability is required. GPT3.5 seems to have great difficulty answering the question, GPT4 can reliably do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Assistants API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Not yet available in Azure OpenAI. Assistants will automatically call built-in tools such as Code Interpreter and Knowledge Retrieval, but will wait for the developer to make Function Calling. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain353py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
